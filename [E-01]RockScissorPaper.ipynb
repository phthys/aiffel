{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21e96fde",
   "metadata": {},
   "source": [
    "# 가위 바위 보 분류기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39a0728d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 불러오기\n",
    "from PIL import Image\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29f31d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 모두 28x28 사이즈로 바꾸어 저장하는 함수\n",
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "382341c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 가위 바위 보 각각의 디렉터리에 들어있는 이미지들의 사이즈를 조절\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5570e557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "def load_data(img_path, number_of_data=300):\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "987c36f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 이미지 불러보기\n",
    "plt.imshow(x_train[50])\n",
    "print('라벨: ', y_train[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e38bd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model에 추가된 Layer 개수:  7\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 26, 26, 256)       7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 11, 11, 500)       1152500   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 5, 5, 500)         0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 12500)             0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               1250100   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 2,410,071\n",
      "Trainable params: 2,410,071\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameter\n",
    "n_channel_1=256\n",
    "n_channel_2=500\n",
    "n_dense=100\n",
    "n_train_epoch=100\n",
    "\n",
    "# 딥러닝 네트워크 모델 설계\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "print('Model에 추가된 Layer 개수: ', len(model.layers))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2877c395",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 1.6578 - accuracy: 0.7433\n",
      "Epoch 2/100\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 0.0908 - accuracy: 0.9700\n",
      "Epoch 3/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.2169 - accuracy: 0.8900\n",
      "Epoch 4/100\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.0228 - accuracy: 0.9933\n",
      "Epoch 5/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 6/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 7/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.4123e-04 - accuracy: 1.0000\n",
      "Epoch 8/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.6632e-04 - accuracy: 1.0000\n",
      "Epoch 9/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.7643e-04 - accuracy: 1.0000\n",
      "Epoch 10/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3876e-04 - accuracy: 1.0000\n",
      "Epoch 11/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1914e-04 - accuracy: 1.0000\n",
      "Epoch 12/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.8521e-05 - accuracy: 1.0000\n",
      "Epoch 13/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.8977e-05 - accuracy: 1.0000\n",
      "Epoch 14/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.7937e-05 - accuracy: 1.0000\n",
      "Epoch 15/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.0436e-05 - accuracy: 1.0000\n",
      "Epoch 16/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.6460e-05 - accuracy: 1.0000\n",
      "Epoch 17/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.8709e-05 - accuracy: 1.0000\n",
      "Epoch 18/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.4561e-05 - accuracy: 1.0000\n",
      "Epoch 19/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.0998e-05 - accuracy: 1.0000\n",
      "Epoch 20/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.9489e-05 - accuracy: 1.0000\n",
      "Epoch 21/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.7113e-05 - accuracy: 1.0000\n",
      "Epoch 22/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.4477e-05 - accuracy: 1.0000\n",
      "Epoch 23/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.1954e-05 - accuracy: 1.0000\n",
      "Epoch 24/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.0185e-05 - accuracy: 1.0000\n",
      "Epoch 25/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8766e-05 - accuracy: 1.0000\n",
      "Epoch 26/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8087e-05 - accuracy: 1.0000\n",
      "Epoch 27/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.6717e-05 - accuracy: 1.0000\n",
      "Epoch 28/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5883e-05 - accuracy: 1.0000\n",
      "Epoch 29/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3801e-05 - accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2652e-05 - accuracy: 1.0000\n",
      "Epoch 31/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2305e-05 - accuracy: 1.0000\n",
      "Epoch 32/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1244e-05 - accuracy: 1.0000\n",
      "Epoch 33/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0795e-05 - accuracy: 1.0000\n",
      "Epoch 34/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1187e-05 - accuracy: 1.0000\n",
      "Epoch 35/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.9157e-06 - accuracy: 1.0000\n",
      "Epoch 36/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.6622e-06 - accuracy: 1.0000\n",
      "Epoch 37/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 8.4905e-06 - accuracy: 1.0000\n",
      "Epoch 38/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.7654e-06 - accuracy: 1.0000\n",
      "Epoch 39/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 7.3978e-06 - accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.9806e-06 - accuracy: 1.0000\n",
      "Epoch 41/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.6683e-06 - accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.3672e-06 - accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 6.0000e-06 - accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.6174e-06 - accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.4000e-06 - accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 5.0206e-06 - accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.7031e-06 - accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.4774e-06 - accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.2501e-06 - accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 4.0268e-06 - accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.8333e-06 - accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.6096e-06 - accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.4665e-06 - accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.2675e-06 - accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 3.1574e-06 - accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.9798e-06 - accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.9202e-06 - accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.8169e-06 - accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.7012e-06 - accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.5864e-06 - accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.5169e-06 - accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.4398e-06 - accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.3389e-06 - accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.3190e-06 - accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.2197e-06 - accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.1589e-06 - accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.0778e-06 - accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 2.0428e-06 - accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.9483e-06 - accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.9165e-06 - accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.9010e-06 - accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.8497e-06 - accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.7373e-06 - accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.7174e-06 - accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.6324e-06 - accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.6145e-06 - accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5465e-06 - accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.5267e-06 - accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4909e-06 - accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.4464e-06 - accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3892e-06 - accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3796e-06 - accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3435e-06 - accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.3010e-06 - accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2668e-06 - accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2541e-06 - accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2350e-06 - accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.2040e-06 - accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1607e-06 - accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1345e-06 - accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.1078e-06 - accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0816e-06 - accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0995e-06 - accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0502e-06 - accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 1.0256e-06 - accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.9420e-07 - accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.8188e-07 - accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.5884e-07 - accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.3738e-07 - accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 9.1950e-07 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f912ece69d0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습시키기\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f418af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n"
     ]
    }
   ],
   "source": [
    "# 테스트용 데이터 만들기\n",
    "\n",
    "# 테스트 이미지 사이즈 조절\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "# x_test, y_test 만들기\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "653ef332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.0688 - accuracy: 0.7767\n",
      "test_loss: 1.0688430070877075 \n",
      "test_accuracy: 0.7766666412353516\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(x_test_norm, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b901909",
   "metadata": {},
   "source": [
    "## 회고\n",
    "첫번째 exploration, 가위 바위 보 분류하기였다.\n",
    "여기서 루브릭 평가 지표로 있었던 train accuracy 60% 이상을 맞춰줘야 하는게 제일 어려웠고 시간이 많이 들어갔다.\n",
    "accuracy를 올려주기 위해 하이퍼 파라메터의 값들을 여러가지로 수정해봤고, 그 중 가장 잘 나온 것이 지금의 상태이다.\n",
    "그리고 또 훈련을 위한 이미지가 문제인가 싶어 훈련이 잘 되도록 손 뒤의 배경을 가려서 찍어 다시 시도해보기도 했다. 이 방법을 시도하니 그래도 accuracy가 어느정도 상승하는걸 볼 수 있었다.\n",
    "조원들과 같이 생각해본 결과 이미지 크기를 28x28로 줄인 것과, 가위 바위 보 각 데이터 개수를 100개로 한정해놓은게 accuracy 값이 잘 나오지 않는 이유가 되지 않을까 싶었다. 이미지 크기의 경우 그만큼 판단해야할 픽셀이 줄어드는 것 때문이고, 데이터 개수도 100개로는 너무 적은 것 같았다.\n",
    "또, 다른 조원들의 사진을 받아와서 테스트 이미지로 사용한 부분도 문제가 되었을 것이라 생각했다. 다른 조원들의 사진과 내 사진은 배경이나 명도 같은 차이들이 있고, 이게 accuracy에 영향을 줬을 것이라 생각하여, 테스트 이미지 또한 내가 또 다시 만든 이미지를 사용해보았다. 이 결과 역시 accuracy가 어느정도 상승하는 것 처럼 보였다.\n",
    "그 결과 위처럼 0.7767, 약 78%를 달성했다!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
